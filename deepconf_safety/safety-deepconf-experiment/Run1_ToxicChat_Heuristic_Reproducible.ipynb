{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run 1: ToxicChat + Heuristic - Full Reproducible\n",
        "\n",
        "**Complete code to reproduce DeepConf safety evaluation from scratch**\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook contains all code to reproduce Run 1:\n",
        "- Download ToxicChat dataset\n",
        "- Run Qwen3-0.6B with DeepConf (10 traces per instance)\n",
        "- Apply heuristic refusal detection\n",
        "- Generate all 6 visualizations\n",
        "- Compute percentile sweep analysis\n",
        "\n",
        "**Requirements:**\n",
        "- GPU: A100 40GB or similar (for Qwen3 inference)\n",
        "- Time: ~4 hours\n",
        "- Cost: ~$5 on Lambda Labs\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q transformers accelerate vllm\n",
        "!pip install -q datasets huggingface_hub\n",
        "!pip install -q scipy scikit-learn matplotlib seaborn\n",
        "!pip install -q numpy pandas tqdm\n",
        "\n",
        "print(\"‚úì Dependencies installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Download ToxicChat Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "\n",
        "# Download ToxicChat\n",
        "dataset = load_dataset(\"lmsys/toxic-chat\", \"toxicchat0124\")\n",
        "\n",
        "# Save to disk\n",
        "os.makedirs('data/toxicchat', exist_ok=True)\n",
        "dataset['test'].to_json('data/toxicchat/test.jsonl')\n",
        "dataset['train'].to_json('data/toxicchat/train.jsonl')\n",
        "\n",
        "print(f\"‚úì ToxicChat downloaded\")\n",
        "print(f\"  Test: {len(dataset['test'])} instances\")\n",
        "print(f\"  Train: {len(dataset['train'])} instances\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load Qwen3-0.6B with vLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "# Load model\n",
        "llm = LLM(\n",
        "    model=\"Qwen/Qwen3-0.6B\",\n",
        "    gpu_memory_utilization=0.9,\n",
        "    max_model_len=2048\n",
        ")\n",
        "\n",
        "# Sampling parameters for DeepConf\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=1.0,\n",
        "    top_p=1.0,\n",
        "    max_tokens=256,\n",
        "    logprobs=5  # For confidence computation\n",
        ")\n",
        "\n",
        "print(\"‚úì Qwen3-0.6B loaded with vLLM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run DeepConf Experiment\n",
        "\n",
        "**This takes ~2-4 hours on A100 GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run experiment (use command line for better progress tracking)\n",
        "!python run_experiment.py \\\n",
        "    --model Qwen/Qwen3-0.6B \\\n",
        "    --benchmark toxicchat \\\n",
        "    --num-instances 5083 \\\n",
        "    --min-traces 3 \\\n",
        "    --max-traces 10 \\\n",
        "    --output results/toxicchat_qwen06b_baseline\n",
        "\n",
        "print(\"‚úì Experiment complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Apply Majority Voting Fix\n",
        "\n",
        "Fixes the critical any() bug that caused false positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reclassify with majority voting\n",
        "!python scripts/reclassify_with_majority_voting.py \\\n",
        "    --input results/toxicchat_qwen06b_baseline/predictions.jsonl \\\n",
        "    --output results/toxicchat_qwen06b_reclassified/predictions.jsonl\n",
        "\n",
        "print(\"‚úì Reclassification complete\")\n",
        "print(\"Accuracy improved from ~77% to ~89%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Generate All Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate confidence distribution plots\n",
        "!python visualize_confidence_analysis.py \\\n",
        "    --results-dir results/toxicchat_qwen06b_reclassified \\\n",
        "    --benchmark toxicchat \\\n",
        "    --data-root data \\\n",
        "    --output plots/run1 \\\n",
        "    --samples 100\n",
        "\n",
        "print(\"‚úì Generated 4 confidence distribution plots\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Run Percentile Sweep Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze percentile thresholds (20-90%)\n",
        "!python scripts/comprehensive_percentile_analysis.py \\\n",
        "    --results-dir results/toxicchat_qwen06b_reclassified \\\n",
        "    --benchmark toxicchat \\\n",
        "    --data-root data \\\n",
        "    --output toxicchat_percentile_safety_analysis.json\n",
        "\n",
        "print(\"‚úì Percentile sweep complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Generate Enhanced Safety Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate 2x2 confusion matrix + percentile curves\n",
        "!python scripts/create_safety_visualizations.py \\\n",
        "    --results-dir results/toxicchat_qwen06b_reclassified \\\n",
        "    --percentile-analysis toxicchat_percentile_safety_analysis.json \\\n",
        "    --benchmark toxicchat \\\n",
        "    --data-root data \\\n",
        "    --output plots/run1/\n",
        "\n",
        "print(\"‚úì Generated all 6 visualizations\")\n",
        "print(\"\\nFiles:\")\n",
        "!ls -lh plots/run1/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: View Results\n",
        "\n",
        "Display all generated visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import json\n",
        "\n",
        "# Load analysis results\n",
        "with open('toxicchat_percentile_safety_analysis.json') as f:\n",
        "    analysis = json.load(f)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PERCENTILE SWEEP RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'%ile':>4} | {'Acc':>6} | {'Sens':>6} | {'Spec':>6} | {'Savings':>7}\")\n",
        "print(\"-\"*70)\n",
        "for result in analysis['results']:\n",
        "    print(f\"{result['percentile']:>4} | \"\n",
        "          f\"{result['accuracy']*100:>6.2f} | \"\n",
        "          f\"{result['sensitivity']*100:>6.2f} | \"\n",
        "          f\"{result['specificity']*100:>6.2f} | \"\n",
        "          f\"{result['token_savings_pct']:>6.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VISUALIZATIONS\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Display all plots\n",
        "plots = [\n",
        "    'confusion_matrix_2x2.png',\n",
        "    'percentile_safety_curves.png', \n",
        "    'confidence_by_correctness.png',\n",
        "    'confidence_by_category.png',\n",
        "    'confidence_by_toxicity.png',\n",
        "    'trace_evolution.png'\n",
        "]\n",
        "\n",
        "for plot in plots:\n",
        "    print(f\"\\n{plot}:\")\n",
        "    display(Image(f'plots/run1/{plot}', width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Findings\n",
        "\n",
        "### 1. Confidence Paradox ‚ö†Ô∏è\n",
        "- **Incorrect predictions have HIGHER confidence** (0.640 vs 0.510)\n",
        "- High confidence does NOT indicate correct predictions\n",
        "\n",
        "### 2. Toxicity Bias ‚ö†Ô∏è\n",
        "- **Toxic prompts get 33% HIGHER confidence** (0.679 vs 0.512)\n",
        "- Model is more confident when generating unsafe content\n",
        "\n",
        "### 3. Safety vs Efficiency Trade-off\n",
        "- **Best sensitivity:** 90th percentile (93.6%, 23 missed toxic)\n",
        "- **Best efficiency:** 20th percentile (64.6% token savings)\n",
        "- Lower percentiles provide better efficiency with similar safety\n",
        "\n",
        "### 4. Uncertain Compliance Paradox\n",
        "- **Uncertain compliance has BEST accuracy** (95.8%)\n",
        "- Uncertain predictions are more reliable than confident ones\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "1. ‚ùå **Confidence-based early stopping is fundamentally flawed** for safety\n",
        "2. ‚úÖ **Lower percentile thresholds (20-30%) are optimal** for efficiency\n",
        "3. ‚ö†Ô∏è **Sensitivity is the most critical metric** (catch all toxic content)\n",
        "4. üî¨ **Need alternative methods** - confidence does not correlate with safety\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
