{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run 2: WildGuardMix + Heuristic - Full Reproducible\n",
        "\n",
        "**Complete code to reproduce DeepConf safety evaluation on WildGuardMix**\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook reproduces Run 2:\n",
        "- Download WildGuardMix dataset (1,725 test instances)\n",
        "- Run Qwen3-0.6B with DeepConf (10 traces per instance)\n",
        "- Apply heuristic refusal detection\n",
        "- Generate all 6 visualizations\n",
        "- Compare to ToxicChat results\n",
        "\n",
        "**Requirements:**\n",
        "- GPU: A100 40GB or similar\n",
        "- Time: ~2 hours (smaller dataset)\n",
        "- Cost: ~$3 on Lambda Labs\n",
        "\n",
        "**Note:** Requires HuggingFace authentication for WildGuardMix\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q transformers accelerate vllm\n",
        "!pip install -q datasets huggingface_hub\n",
        "!pip install -q scipy scikit-learn matplotlib seaborn\n",
        "!pip install -q numpy pandas tqdm\n",
        "\n",
        "print(\"✓ Dependencies installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: HuggingFace Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Login to HuggingFace (required for WildGuardMix)\n",
        "# Get your token from: https://huggingface.co/settings/tokens\n",
        "login()\n",
        "\n",
        "print(\"✓ HuggingFace authentication complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Download WildGuardMix Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python download_wildguardmix.py\n",
        "\n",
        "print(\"✓ WildGuardMix downloaded\")\n",
        "print(\"  Test: 1,725 instances\")\n",
        "print(\"  Train: 86,759 instances\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run DeepConf Experiment\n",
        "\n",
        "**Takes ~1-2 hours on A100 GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run experiment on WildGuardMix\n",
        "!python run_experiment.py \\\n",
        "    --model Qwen/Qwen3-0.6B \\\n",
        "    --benchmark wildguardmix \\\n",
        "    --num-instances 1725 \\\n",
        "    --min-traces 3 \\\n",
        "    --max-traces 10 \\\n",
        "    --output results/wildguardmix_qwen06b_baseline\n",
        "\n",
        "print(\"✓ Experiment complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Generate Confidence Distribution Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python visualize_confidence_analysis.py \\\n",
        "    --results-dir results/wildguardmix_qwen06b_baseline \\\n",
        "    --benchmark wildguardmix \\\n",
        "    --data-root data \\\n",
        "    --output plots/run2 \\\n",
        "    --samples 100\n",
        "\n",
        "print(\"✓ Generated 4 confidence distribution plots\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Run Percentile Sweep Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python scripts/comprehensive_percentile_analysis.py \\\n",
        "    --results-dir results/wildguardmix_qwen06b_baseline \\\n",
        "    --benchmark wildguardmix \\\n",
        "    --data-root data \\\n",
        "    --output wildguardmix_percentile_safety_analysis.json\n",
        "\n",
        "print(\"✓ Percentile sweep complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Generate Enhanced Safety Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python scripts/create_safety_visualizations.py \\\n",
        "    --results-dir results/wildguardmix_qwen06b_baseline \\\n",
        "    --percentile-analysis wildguardmix_percentile_safety_analysis.json \\\n",
        "    --benchmark wildguardmix \\\n",
        "    --data-root data \\\n",
        "    --output plots/run2/\n",
        "\n",
        "print(\"✓ All 6 visualizations generated\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: View Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import json\n",
        "\n",
        "# Load analysis results\n",
        "with open('wildguardmix_percentile_safety_analysis.json') as f:\n",
        "    analysis = json.load(f)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PERCENTILE SWEEP RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'%ile':>4} | {'Acc':>6} | {'Sens':>6} | {'Spec':>6} | {'Savings':>7}\")\n",
        "print(\"-\"*70)\n",
        "for result in analysis['results']:\n",
        "    print(f\"{result['percentile']:>4} | \"\n",
        "          f\"{result['accuracy']*100:>6.2f} | \"\n",
        "          f\"{result['sensitivity']*100:>6.2f} | \"\n",
        "          f\"{result['specificity']*100:>6.2f} | \"\n",
        "          f\"{result['token_savings_pct']:>6.1f}%\")\n",
        "\n",
        "# Display all plots\n",
        "plots = [\n",
        "    'confusion_matrix_2x2.png',\n",
        "    'percentile_safety_curves.png',\n",
        "    'confidence_by_correctness.png',\n",
        "    'confidence_by_category.png',\n",
        "    'confidence_by_toxicity.png',\n",
        "    'trace_evolution.png'\n",
        "]\n",
        "\n",
        "for plot in plots:\n",
        "    print(f\"\\n{plot}:\")\n",
        "    display(Image(f'plots/run2/{plot}', width=800))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Findings\n",
        "\n",
        "### 1. Better Accuracy than ToxicChat ✅\n",
        "- **WildGuardMix:** 41-42% accuracy\n",
        "- **ToxicChat:** 9-10% accuracy\n",
        "- +32% absolute improvement\n",
        "\n",
        "### 2. Minimal Confidence Bias ✅\n",
        "- Incorrect: 0.655 confidence\n",
        "- Correct: 0.640 confidence  \n",
        "- Only 2% difference (vs 25% in ToxicChat)\n",
        "\n",
        "### 3. No Toxicity Confidence Bias ✅\n",
        "- Toxic prompts: 0.648 confidence\n",
        "- Safe prompts: 0.646 confidence\n",
        "- Nearly identical (vs 33% difference in ToxicChat)\n",
        "\n",
        "### 4. Similar Sensitivity ✅\n",
        "- 92% toxic catch rate (vs 91-94% in ToxicChat)\n",
        "- Consistent safety performance\n",
        "\n",
        "---\n",
        "\n",
        "## WildGuardMix vs ToxicChat Comparison\n",
        "\n",
        "| Metric | ToxicChat | WildGuardMix | Winner |\n",
        "|--------|-----------|--------------|--------|\n",
        "| Accuracy | 9-10% | 41-42% | ✅ WildGuardMix |\n",
        "| Sensitivity | 91-94% | 92% | ≈ Tie |\n",
        "| Specificity | 2-4% | 2% | ≈ Tie |\n",
        "| Confidence bias (incorrect) | +25% | +2% | ✅ WildGuardMix |\n",
        "| Confidence bias (toxic) | +33% | 0% | ✅ WildGuardMix |\n",
        "| Token savings | 64.6% | 64.3% | ≈ Tie |\n",
        "\n",
        "### Why WildGuardMix is Better\n",
        "\n",
        "1. **Gold-standard labels** - Expert-annotated refusal + harmfulness\n",
        "2. **Balanced dataset** - 44% toxic vs 7% in ToxicChat\n",
        "3. **Better coverage** - Diverse adversarial examples\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "1. ✅ **WildGuardMix provides better evaluation** - Higher quality labels\n",
        "2. ✅ **Less confidence bias** - But still present (incorrect > correct)\n",
        "3. ✅ **Similar efficiency gains** - 64% token savings at 20th percentile\n",
        "4. ⚠️ **Dataset quality matters** - ToxicChat may have labeling issues\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
